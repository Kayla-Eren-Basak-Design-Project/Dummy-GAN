{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15fef83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8aeb5075",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "MAP_SIZE = 32\n",
    "LR_D = LR_G = 0.00005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c09eca31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(216225, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "N = 32\n",
    "\n",
    "def generate_rect(x, y, w, h):\n",
    "  data = np.zeros((N,N))\n",
    "  data[x:x+w+1, y:y+h+1] = 1\n",
    "  data[x+1:x+w, y+1:y+h] = 0\n",
    "  #data = np.reshape(data, (N*N))\n",
    "  return data\n",
    "\n",
    "train_images = []\n",
    "\n",
    "for x in range(0, N-2):\n",
    "  for y in range(0, N-2):\n",
    "    for w in range(2,N):\n",
    "      for h in range(2,N):\n",
    "        if x+w<N and y+h<N:\n",
    "          train_images.append(generate_rect(x,y,w,h))\n",
    "train_images = np.array(train_images).astype('int32')\n",
    "#train_images = train_images[np.random.choice(np.shape(train_images)[0], 20000, replace=False)]\n",
    "\n",
    "print(np.shape(train_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b73245b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1518e6fa5e0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_images[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46488af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "(216225, 32, 32, 2)\n",
      "(216225, 32, 32, 2)\n",
      "(216225, 32, 32, 2)\n"
     ]
    }
   ],
   "source": [
    "train_size, x_dims, y_dims = train_images.shape\n",
    "z_dims = np.amax(train_images) + 1 # Number of different title types\n",
    "print(z_dims)\n",
    "train_images_onehot = np.eye(z_dims, dtype='uint8')[train_images]\n",
    "print(train_images_onehot.shape) # (train_size, x_dims, y_dims, z_dims)\n",
    "\n",
    "train_images = np.zeros((train_size, MAP_SIZE, MAP_SIZE, z_dims))\n",
    "print(train_images.shape)\n",
    "\n",
    "# TODO: Change empty space encoding here if different\n",
    "train_images[:, :, :, 1] = 0.0  # Fill with empty space \n",
    "\n",
    "train_images[:train_size, :x_dims, :y_dims, :] = train_images_onehot\n",
    "print(train_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d9cf213",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_images():\n",
    "    sample_images = train_images[np.random.choice(np.shape(train_images)[0], 2000, replace=False)]\n",
    "    train_size, x_dims, y_dims = sample_images.shape\n",
    "    z_dims = np.amax(sample_images) + 1 # Number of different title types\n",
    "    train_images_onehot = np.eye(z_dims, dtype='uint8')[sample_images]\n",
    "\n",
    "    sample_images = np.zeros((train_size, MAP_SIZE, MAP_SIZE, z_dims))\n",
    "\n",
    "    # TODO: Change empty space encoding here if different\n",
    "    sample_images[:, :, :, 1] = 0.0  # Fill with empty space \n",
    "\n",
    "    sample_images[:train_size, :x_dims, :y_dims, :] = train_images_onehot\n",
    "    sample_dataset = tf.data.Dataset.from_tensor_slices(sample_images).shuffle(sample_images.shape[0]).batch(BATCH_SIZE)\n",
    "    \n",
    "    return (sample_dataset)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a86c5543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x151461c9a00>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAL+0lEQVR4nO3dUaicdX6H8efb5Jitq7C62pDG0OxaafGiG+UQLCvLdrdubW5UKEUvFi+ELGUFhe1F2EJroRduqUoviiVW2VCs1lbFUKRuGgRZKNGjjTGa1rjiskljslsr2kJjEn+9mDdwIufkTGbemYn7fz5wODPvvDPvj5c8Z2bec/JOqgpJP/9+YdYDSJoOY5caYexSI4xdaoSxS40wdqkRq8e5c5Ibgb8EVgF/U1X3nm39yy5dVRs3zI2zyV68ue/CWY8gTcT/8b98VMez1G0jx55kFfBXwA3AIeClJDur6o3l7rNxwxwvPrdh1E325nd+edOsR5AmYk/tXva2cV7Gbwbeqqq3q+oj4HHgpjEeT9IEjRP7euAni64f6pZJOg9N/ABdkq1JFpIs/PS/Tk16c5KWMU7sh4HFb8Cv6Jadoaq2V9V8Vc1f/vlVY2xO0jjGif0l4KokX0hyAXArsLOfsST1beSj8VV1MsmdwHMMfvX2SFW9Purj9X2E/Ln/3Nvr40mfdmP9nr2qngWe7WkWSRPkX9BJjTB2qRHGLjXC2KVGGLvUiLGOxvfJX5VJk+Uzu9QIY5caYexSI4xdaoSxS42Y6tH4N/dd6CmhpBnxmV1qhLFLjTB2qRHGLjXC2KVGGLvUCGOXGmHsUiOMXWqEsUuNMHapEcYuNcLYpUaM9b/ekrwDfAicAk5W1XwfQ0nqXx//xfW3qupnPTyOpAnyZbzUiHFjL+AHSV5OsrWPgSRNxrgv46+vqsNJfgnYleTfq+qFxSt0PwS2AnyGC8fcnKRRjfXMXlWHu+/HgKeBzUuss72q5qtqfo4142xO0hhGjj3JZ5NcfPoy8A1gf1+DSerXOC/j1wJPJzn9OH9XVf/cy1SSejdy7FX1NvClHmeRNEH+6k1qhLFLjTB2qRHGLjXC2KVGGLvUCGOXGmHsUiOMXWqEsUuNMHapEcYuNcLYpUYYu9QIY5caYexSI4xdaoSxS40wdqkRxi41wtilRhi71Ahjlxph7FIjjF1qxIqxJ3kkybEk+xctuzTJriQHu++XTHZMSeMa5pn9+8CNn1i2DdhdVVcBu7vrks5jK8befd76e59YfBOwo7u8A7i537Ek9W3U9+xrq+pId/ldBp/oKuk8NvYBuqoqoJa7PcnWJAtJFk5wfNzNSRrRqLEfTbIOoPt+bLkVq2p7Vc1X1fwca0bcnKRxjRr7TuD27vLtwDP9jCNpUob51dtjwL8Cv5bkUJI7gHuBG5IcBH67uy7pPLZ6pRWq6rZlbvp6z7NImiD/gk5qhLFLjTB2qRHGLjXC2KVGGLvUCGOXGmHsUiOMXWqEsUuNMHapEcYuNcLYpUYYu9QIY5caYexSI4xdaoSxS40wdqkRxi41wtilRhi71Ahjlxph7FIjjF1qxDAf//RIkmNJ9i9adk+Sw0n2dl9bJjumpHEN88z+feDGJZY/UFWbuq9n+x1LUt9WjL2qXgDem8IskiZonPfsdybZ173Mv6S3iSRNxKixPwhcCWwCjgD3Lbdikq1JFpIsnOD4iJuTNK6RYq+qo1V1qqo+Bh4CNp9l3e1VNV9V83OsGXVOSWMaKfYk6xZdvQXYv9y6ks4Pq1daIcljwFeBy5IcAv4E+GqSTUAB7wDfmtyIkvqwYuxVddsSix+ewCySJsi/oJMaYexSI4xdaoSxS40wdqkRxi41wtilRhi71Ahjlxph7FIjjF1qhLFLjTB2qRHGLjXC2KVGGLvUCGOXGmHsUiOMXWqEsUuNMHapEcYuNcLYpUYYu9QIY5casWLsSTYkeT7JG0leT3JXt/zSJLuSHOy++7HN0nlsmGf2k8B3qupq4Drg20muBrYBu6vqKmB3d13SeWrF2KvqSFW90l3+EDgArAduAnZ0q+0Abp7QjJJ6cE7v2ZNsBK4B9gBrq+pId9O7wNp+R5PUp6FjT3IR8CRwd1V9sPi2qioGH9+81P22JllIsnCC42MNK2l0Q8WeZI5B6I9W1VPd4qNJ1nW3rwOOLXXfqtpeVfNVNT/Hmj5mljSCYY7Gh8HnsR+oqvsX3bQTuL27fDvwTP/jSerL6iHW+TLwTeC1JHu7Zd8F7gWeSHIH8GPg9ycyoaRerBh7Vf0QyDI3f73fcSRNin9BJzXC2KVGGLvUCGOXGmHsUiOMXWqEsUuNMHapEcYuNcLYpUYYu9QIY5caYexSI4xdaoSxS40wdqkRxi41wtilRhi71Ahjlxph7FIjjF1qhLFLjTB2qRHGLjVimM9625Dk+SRvJHk9yV3d8nuSHE6yt/vaMvlxJY1qmM96Owl8p6peSXIx8HKSXd1tD1TVX0xuPEl9Geaz3o4AR7rLHyY5AKyf9GCS+nVO79mTbASuAfZ0i+5Msi/JI0ku6Xs4Sf0ZOvYkFwFPAndX1QfAg8CVwCYGz/z3LXO/rUkWkiyc4Pj4E0sayVCxJ5ljEPqjVfUUQFUdrapTVfUx8BCwean7VtX2qpqvqvk51vQ1t6RzNMzR+AAPAweq6v5Fy9ctWu0WYH//40nqyzBH478MfBN4Lcnebtl3gduSbAIKeAf41gTmk9STYY7G/xDIEjc92/84kibFv6CTGmHsUiOMXWqEsUuNMHapEcYuNcLYpUYYu9QIY5caYexSI4xdaoSxS40wdqkRxi41wtilRhi71Ahjlxph7FIjjF1qhLFLjTB2qRHGLjXC2KVGGLvUCGOXGjHMZ719JsmLSV5N8nqSP+2WfyHJniRvJfn7JBdMflxJoxrmmf048LWq+hKDj2e+Mcl1wPeAB6rqV4H/Bu6Y2JSSxrZi7DXwP93Vue6rgK8B/9gt3wHcPIkBJfVj2M9nX9V9gusxYBfwI+D9qjrZrXIIWD+RCSX1YqjYq+pUVW0CrgA2A78+7AaSbE2ykGThBMdHm1LS2M7paHxVvQ88D/wm8Lkkpz/y+Qrg8DL32V5V81U1P8eacWaVNIZhjsZfnuRz3eVfBG4ADjCI/ve61W4HnpnQjJJ6sHrlVVgH7EiyisEPhyeq6p+SvAE8nuTPgH8DHp7gnJLGtGLsVbUPuGaJ5W8zeP8u6VPAv6CTGmHsUiOMXWqEsUuNMHapEamq6W0s+Snw4+7qZcDPprbx5TnHmZzjTJ+2OX6lqi5f6oapxn7GhpOFqpqfycadwzkanMOX8VIjjF1qxCxj3z7DbS/mHGdyjjP93Mwxs/fskqbLl/FSI2YSe5Ibk/xHd7LKbbOYoZvjnSSvJdmbZGGK230kybEk+xctuzTJriQHu++XzGiOe5Ic7vbJ3iRbpjDHhiTPJ3mjO6npXd3yqe6Ts8wx1X0ysZO8VtVUv4BVDE5r9UXgAuBV4Oppz9HN8g5w2Qy2+xXgWmD/omV/DmzrLm8DvjejOe4B/nDK+2MdcG13+WLgTeDqae+Ts8wx1X0CBLiouzwH7AGuA54Abu2W/zXwB+fyuLN4Zt8MvFVVb1fVR8DjwE0zmGNmquoF4L1PLL6JwYk7YUon8FxmjqmrqiNV9Up3+UMGJ0dZz5T3yVnmmKoa6P0kr7OIfT3wk0XXZ3myygJ+kOTlJFtnNMNpa6vqSHf5XWDtDGe5M8m+7mX+xN9OLJZkI4PzJ+xhhvvkE3PAlPfJJE7y2voBuuur6lrgd4FvJ/nKrAeCwU92Bj+IZuFB4EoGnxFwBLhvWhtOchHwJHB3VX2w+LZp7pMl5pj6PqkxTvK6nFnEfhjYsOj6siernLSqOtx9PwY8zWzPvHM0yTqA7vuxWQxRVUe7f2gfAw8xpX2SZI5BYI9W1VPd4qnvk6XmmNU+6bb9Pud4ktflzCL2l4CruiOLFwC3AjunPUSSzya5+PRl4BvA/rPfa6J2MjhxJ8zwBJ6n4+rcwhT2SZIwOIfhgaq6f9FNU90ny80x7X0ysZO8TusI4yeONm5hcKTzR8AfzWiGLzL4TcCrwOvTnAN4jMHLwRMM3nvdAXwe2A0cBP4FuHRGc/wt8Bqwj0Fs66Ywx/UMXqLvA/Z2X1umvU/OMsdU9wnwGwxO4rqPwQ+WP170b/ZF4C3gH4A15/K4/gWd1IjWD9BJzTB2qRHGLjXC2KVGGLvUCGOXGmHsUiOMXWrE/wNjqfwazNsgNgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.argmax(train_images[2], axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eeba46c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_tensor_slices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_images\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshuffle(train_images\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mbatch(BATCH_SIZE)\n",
      "File \u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:793\u001b[0m, in \u001b[0;36mDatasetV2.from_tensor_slices\u001b[1;34m(tensors, name)\u001b[0m\n\u001b[0;32m    715\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    716\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_tensor_slices\u001b[39m(tensors, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    717\u001b[0m   \u001b[38;5;124;03m\"\"\"Creates a `Dataset` whose elements are slices of the given tensors.\u001b[39;00m\n\u001b[0;32m    718\u001b[0m \n\u001b[0;32m    719\u001b[0m \u001b[38;5;124;03m  The given tensors are sliced along their first dimension. This operation\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    791\u001b[0m \u001b[38;5;124;03m    Dataset: A `Dataset`.\u001b[39;00m\n\u001b[0;32m    792\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 793\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mTensorSliceDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:4477\u001b[0m, in \u001b[0;36mTensorSliceDataset.__init__\u001b[1;34m(self, element, is_files, name)\u001b[0m\n\u001b[0;32m   4475\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, element, is_files\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   4476\u001b[0m   \u001b[38;5;124;03m\"\"\"See `Dataset.from_tensor_slices()` for details.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 4477\u001b[0m   element \u001b[38;5;241m=\u001b[39m \u001b[43mstructure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43melement\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4478\u001b[0m   batched_spec \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mtype_spec_from_value(element)\n\u001b[0;32m   4479\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensors \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mto_batched_tensor_list(batched_spec, element)\n",
      "File \u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py:125\u001b[0m, in \u001b[0;36mnormalize_element\u001b[1;34m(element, element_signature)\u001b[0m\n\u001b[0;32m    122\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    123\u001b[0m         dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(spec, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    124\u001b[0m         normalized_components\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 125\u001b[0m             \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcomponent_\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m nest\u001b[38;5;241m.\u001b[39mpack_sequence_as(pack_as, normalized_components)\n",
      "File \u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\tensorflow\\python\\profiler\\trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    181\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m Trace(trace_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrace_kwargs):\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1695\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconvert_to_tensor did not convert to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1691\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe preferred dtype: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m vs \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1692\u001b[0m                       (ret\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mbase_dtype, preferred_dtype\u001b[38;5;241m.\u001b[39mbase_dtype))\n\u001b[0;32m   1694\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1695\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1697\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[0;32m   1698\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_conversion_registry.py:48\u001b[0m, in \u001b[0;36m_default_conversion_function\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_default_conversion_function\u001b[39m(value, dtype, name, as_ref):\n\u001b[0;32m     47\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m as_ref  \u001b[38;5;66;03m# Unused.\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconstant_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:267\u001b[0m, in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstant\u001b[39m(value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    172\u001b[0m   \u001b[38;5;124;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \n\u001b[0;32m    174\u001b[0m \u001b[38;5;124;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;124;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:279\u001b[0m, in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.constant\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    278\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[1;32m--> 279\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_eager_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    281\u001b[0m g \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mget_default_graph()\n\u001b[0;32m    282\u001b[0m tensor_value \u001b[38;5;241m=\u001b[39m attr_value_pb2\u001b[38;5;241m.\u001b[39mAttrValue()\n",
      "File \u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:304\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[1;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_eager_impl\u001b[39m(ctx, value, dtype, shape, verify_shape):\n\u001b[0;32m    303\u001b[0m   \u001b[38;5;124;03m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 304\u001b[0m   t \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_eager_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    305\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "File \u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[0;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(train_images.shape[0]).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a968085",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.initializers import RandomNormal\n",
    "from keras.layers import Dense, Conv2D, Flatten, Reshape, Dropout, LeakyReLU, Conv2DTranspose\n",
    "from keras.models import Sequential\n",
    "img_cols, img_rows, channels = 32,32,2\n",
    "optimizer = tf.optimizers.Adam(0.0002, 0.5)\n",
    "noise_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81c346ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discriminator_model(n_extra_layers=0):\n",
    "   discriminator = Sequential()\n",
    "\n",
    "   discriminator.add(Dense(1024, input_dim=img_rows*img_cols*channels))\n",
    "   discriminator.add(LeakyReLU(0.2))\n",
    "\n",
    "   discriminator.add(Dense(512))\n",
    "   discriminator.add(LeakyReLU(0.2))\n",
    "\n",
    "   discriminator.add(Dense(256))\n",
    "   discriminator.add(LeakyReLU(0.2))\n",
    "\n",
    "   discriminator.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "   discriminator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "   return discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82a32547",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator_model(n_extra_layers=0):\n",
    "   generator = Sequential()\n",
    "    \n",
    "   generator.add(Dense(256, input_dim=noise_dim))\n",
    "   generator.add(LeakyReLU(0.2))\n",
    "\n",
    "   generator.add(Dense(512))\n",
    "   generator.add(LeakyReLU(0.2))\n",
    "\n",
    "   generator.add(Dense(1024))\n",
    "   generator.add(LeakyReLU(0.2))\n",
    "\n",
    "   generator.add(Dense(img_rows*img_cols*channels, activation='tanh'))\n",
    "    \n",
    "   generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "   return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fc2df80",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = make_discriminator_model()\n",
    "generator = make_generator_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c002f889",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 1024)              2098176   \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 256)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,754,561\n",
      "Trainable params: 2,754,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 256)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 512)               131584    \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 512)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1024)              525312    \n",
      "                                                                 \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 2048)              2099200   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,789,120\n",
      "Trainable params: 2,789,120\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(discriminator.summary())\n",
    "print(generator.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e65f43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2048)\n",
      "(1, 1)\n"
     ]
    }
   ],
   "source": [
    "print(generator(np.random.rand(1, 128)).shape)\n",
    "print(discriminator(np.random.rand(1, MAP_SIZE*MAP_SIZE*z_dims)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a74a6c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_discriminator_loss(real_output, generated_output):\n",
    "  real_loss = tf.reduce_mean(real_output)\n",
    "  generated_loss = tf.reduce_mean(generated_output)\n",
    "  total_loss = real_loss - generated_loss\n",
    "\n",
    "  return total_loss\n",
    "\n",
    "\n",
    "def get_generator_loss(generated_output):\n",
    "  return -tf.reduce_mean(generated_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62374aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_optimizer = tf.optimizers.RMSprop(LR_D)\n",
    "generator_optimizer = tf.optimizers.RMSprop(LR_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc2a3327",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input, savefig=False):\n",
    "  predictions = model(test_input, training=False)\n",
    "\n",
    "  fig = plt.figure(figsize=(10, 10))\n",
    "\n",
    "  for i in range(predictions.shape[0]):\n",
    "    plt.subplot(4, 4, i+1)\n",
    "    plt.imshow(np.argmax(predictions[i], axis=2))\n",
    "    plt.axis('off')\n",
    "\n",
    "  if savefig:\n",
    "    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae9c3dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10000\n",
    "noise_size = 128\n",
    "num_examples = 8\n",
    "\n",
    "# Use same random vector to see evolution of generated images over time\n",
    "random_vector_for_generation = tf.random.normal([num_examples, noise_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1e63ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(images, update_generator=False):\n",
    "  # Generating noise from a normal distribution\n",
    "  noise = tf.random.normal([BATCH_SIZE, noise_size])\n",
    "\n",
    "  for w in discriminator.trainable_variables:\n",
    "    w.assign(tf.clip_by_value(w, -0.01, 0.01))\n",
    "    \n",
    "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "    generated_images = generator(noise, training=True)\n",
    "    real_output = discriminator(images, training=True)\n",
    "    generated_output = discriminator(generated_images, training=True)\n",
    "\n",
    "    gen_loss = get_generator_loss(generated_output)\n",
    "    disc_loss = get_discriminator_loss(real_output, generated_output)\n",
    "        \n",
    "    gradients_of_discriminator = disc_tape.gradient(-disc_loss, discriminator.trainable_variables)\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "    if update_generator:\n",
    "      gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "      generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "\n",
    "  return gen_loss, disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88574fd9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(\u001b[43mtrain_dataset\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ca638373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "  gen_iterations = 0\n",
    "  for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "    disc_iterations = 0\n",
    "    \n",
    "    sample_images = train_images[np.random.choice(np.shape(train_images)[0], 2000, replace=False)]\n",
    "    train_size, x_dims, y_dims = sample_images.shape\n",
    "    z_dims = np.amax(sample_images) + 1 # Number of different title types\n",
    "    train_images_onehot = np.eye(z_dims, dtype='uint8')[sample_images]\n",
    "\n",
    "    sample_images = np.zeros((train_size, MAP_SIZE, MAP_SIZE, z_dims))\n",
    "\n",
    "    # TODO: Change empty space encoding here if different\n",
    "    sample_images[:, :, :, 1] = 0.0  # Fill with empty space \n",
    "\n",
    "    sample_images[:train_size, :x_dims, :y_dims, :] = train_images_onehot\n",
    "    sample_dataset = tf.data.Dataset.from_tensor_slices(sample_images).shuffle(sample_images.shape[0]).batch(BATCH_SIZE)\n",
    "    \n",
    "    for i, images in enumerate(sample_dataset):\n",
    "      images = np.reshape(images, (images.shape[0],img_rows*img_cols*channels))\n",
    "      if disc_iterations == 0:\n",
    "        if gen_iterations < 25 or gen_iterations % 500 == 0:\n",
    "          disc_iterations = 100\n",
    "        else:\n",
    "          disc_iterations = 5\n",
    "      if disc_iterations == 1 or i == len(sample_dataset) - 1:\n",
    "        gen_loss, disc_loss = train_step(images, True)\n",
    "        gen_iterations += 1\n",
    "      else:\n",
    "        gen_loss, disc_loss = train_step(images)\n",
    "      disc_iterations -= 1\n",
    "\n",
    "    #display.clear_output(wait=True)\n",
    "    # Save generator every 500 epochs\n",
    "    if (epoch + 1) % 500 == 0:\n",
    "        print(\"Epoch: \", epoch)\n",
    "        print(\"Generator Loss: \", gen_loss)\n",
    "        print(\"Discriminator Loss: \", disc_loss)\n",
    "    #  generate_and_save_images(generator, epoch + 1, \n",
    "    #                           random_vector_for_generation, True)\n",
    "    #  generator.save('models/generator_baseline_' + str(epoch + 1))\n",
    "    #else:\n",
    "    #  generate_and_save_images(generator, epoch + 1, \n",
    "    #                           random_vector_for_generation)\n",
    "\n",
    "    #print ('Time taken for epoch {} is {} sec'.format(epoch + 1, \n",
    "    #                                                  time.time() - start))\n",
    "    #print(\"Generator Loss: \", gen_loss)\n",
    "    #print(\"Discriminator Loss: \", disc_loss)\n",
    "  # Generate after the final epoch\n",
    "  #display.clear_output(wait=True)\n",
    "  #generate_and_save_images(generator,\n",
    "  #                        epochs,\n",
    "  #                        random_vector_for_generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3f4dc458",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [30]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [29]\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(dataset, epochs)\u001b[0m\n\u001b[0;32m     26\u001b[0m     disc_iterations \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m disc_iterations \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(sample_dataset) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 28\u001b[0m   gen_loss, disc_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m   gen_iterations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36mtrain_step\u001b[1;34m(images, update_generator)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m gen_tape, tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m disc_tape:\n\u001b[0;32m      9\u001b[0m   generated_images \u001b[38;5;241m=\u001b[39m generator(noise, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 10\u001b[0m   real_output \u001b[38;5;241m=\u001b[39m \u001b[43mdiscriminator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m   generated_output \u001b[38;5;241m=\u001b[39m discriminator(generated_images, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     13\u001b[0m   gen_loss \u001b[38;5;241m=\u001b[39m get_generator_loss(generated_output)\n",
      "File \u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\keras\\engine\\base_layer.py:1041\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1038\u001b[0m \u001b[38;5;66;03m# Accept NumPy and scalar inputs by converting to Tensors.\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, (\n\u001b[0;32m   1040\u001b[0m     tf\u001b[38;5;241m.\u001b[39mTensor, np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mint\u001b[39m)) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m input_list):\n\u001b[1;32m-> 1041\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_convert_numpy_or_python_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1042\u001b[0m   input_list \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(inputs)\n\u001b[0;32m   1044\u001b[0m \u001b[38;5;66;03m# Handle `mask` propagation from previous layer to current layer. Masks can\u001b[39;00m\n\u001b[0;32m   1045\u001b[0m \u001b[38;5;66;03m# be propagated explicitly via the `mask` argument, or implicitly via\u001b[39;00m\n\u001b[0;32m   1046\u001b[0m \u001b[38;5;66;03m# setting the `_keras_mask` attribute on the inputs to a Layer. Masks passed\u001b[39;00m\n\u001b[0;32m   1047\u001b[0m \u001b[38;5;66;03m# explicitly take priority.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:914\u001b[0m, in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    910\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m    911\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 914\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    915\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:914\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    910\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m    911\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 914\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    915\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\keras\\engine\\base_layer.py:3382\u001b[0m, in \u001b[0;36m_convert_numpy_or_python_types\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   3380\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_convert_numpy_or_python_types\u001b[39m(x):\n\u001b[0;32m   3381\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, (tf\u001b[38;5;241m.\u001b[39mTensor, np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mint\u001b[39m)):\n\u001b[1;32m-> 3382\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3383\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1081\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1082\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1083\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m   1084\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1086\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1559\u001b[0m, in \u001b[0;36mconvert_to_tensor_v2_with_dispatch\u001b[1;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[0;32m   1495\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconvert_to_tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;129m@dispatch\u001b[39m\u001b[38;5;241m.\u001b[39madd_dispatch_support\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_to_tensor_v2_with_dispatch\u001b[39m(\n\u001b[0;32m   1498\u001b[0m     value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype_hint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1499\u001b[0m   \u001b[38;5;124;03m\"\"\"Converts the given `value` to a `Tensor`.\u001b[39;00m\n\u001b[0;32m   1500\u001b[0m \n\u001b[0;32m   1501\u001b[0m \u001b[38;5;124;03m  This function converts Python objects of various types to `Tensor`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;124;03m    ValueError: If the `value` is a tensor not of given `dtype` in graph mode.\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1559\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconvert_to_tensor_v2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1560\u001b[0m \u001b[43m      \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype_hint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_hint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1565\u001b[0m, in \u001b[0;36mconvert_to_tensor_v2\u001b[1;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[0;32m   1563\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_to_tensor_v2\u001b[39m(value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype_hint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1564\u001b[0m   \u001b[38;5;124;03m\"\"\"Converts the given `value` to a `Tensor`.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1565\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1566\u001b[0m \u001b[43m      \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1567\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1568\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1569\u001b[0m \u001b[43m      \u001b[49m\u001b[43mpreferred_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_hint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1570\u001b[0m \u001b[43m      \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\tensorflow\\python\\profiler\\trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    181\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m Trace(trace_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrace_kwargs):\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1695\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconvert_to_tensor did not convert to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1691\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe preferred dtype: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m vs \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1692\u001b[0m                       (ret\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mbase_dtype, preferred_dtype\u001b[38;5;241m.\u001b[39mbase_dtype))\n\u001b[0;32m   1694\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1695\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1697\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[0;32m   1698\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_conversion_registry.py:48\u001b[0m, in \u001b[0;36m_default_conversion_function\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_default_conversion_function\u001b[39m(value, dtype, name, as_ref):\n\u001b[0;32m     47\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m as_ref  \u001b[38;5;66;03m# Unused.\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconstant_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:267\u001b[0m, in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstant\u001b[39m(value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    172\u001b[0m   \u001b[38;5;124;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \n\u001b[0;32m    174\u001b[0m \u001b[38;5;124;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;124;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:279\u001b[0m, in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.constant\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    278\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[1;32m--> 279\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_eager_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    281\u001b[0m g \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mget_default_graph()\n\u001b[0;32m    282\u001b[0m tensor_value \u001b[38;5;241m=\u001b[39m attr_value_pb2\u001b[38;5;241m.\u001b[39mAttrValue()\n",
      "File \u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:304\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[1;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_eager_impl\u001b[39m(ctx, value, dtype, shape, verify_shape):\n\u001b[0;32m    303\u001b[0m   \u001b[38;5;124;03m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 304\u001b[0m   t \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_eager_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    305\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(2, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294e7e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(noise):\n",
    "    generated_images = generator.predict(noise)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i, image in enumerate(generated_images):\n",
    "        plt.subplot(10, 10, i+1)\n",
    "        if 2 == 1:\n",
    "            plt.imshow(image.reshape((32, 32)), cmap='gray')\n",
    "        else:\n",
    "            plt.imshow(np.argmax(image.reshape(32, 32, 2), axis=2))\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635fd337",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = np.random.normal(0, 1, size=(100, noise_dim))\n",
    "show_images(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8955eb51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
