{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNR8Fy0TxoM6lW7kRwhe8Y+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kayla-Eren-Basak-Design-Project/Dummy-GAN/blob/Basak/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bYvfPDvrEGbw"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import time\n",
        "import json\n",
        "\n",
        "from IPython import display"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "MAP_SIZE = 32\n",
        "LR_D = LR_G = 0.00005"
      ],
      "metadata": {
        "id": "XZD0pMrvEJln"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N = 5\n",
        "\n",
        "def generate_rect(x, y, w, h):\n",
        "  data = np.zeros((N,N))\n",
        "  data[x:x+w+1, y:y+h+1] = 1\n",
        "  data[x+1:x+w, y+1:y+h] = 0\n",
        "  #data = np.reshape(data, (N*N))\n",
        "  return data\n",
        "\n",
        "train_images = []\n",
        "\n",
        "for x in range(0, N-2):\n",
        "  for y in range(0, N-2):\n",
        "    for w in range(2,N):\n",
        "      for h in range(2,N):\n",
        "        if x+w<N and y+h<N:\n",
        "          train_images.append(generate_rect(x,y,w,h))\n",
        "train_images = np.array(train_images).astype('int32')\n",
        "#arr = arr[np.random.choice(123201, 60000, replace=False)]\n",
        "\n",
        "print(np.shape(train_images))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdlZFdPgEWZ8",
        "outputId": "9e522998-cb03-4355-d67e-ac9119b56653"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(36, 5, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(train_images[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "OSlpmuZ6Eec9",
        "outputId": "22f4935e-9aa5-4bba-fec0-114f995c7c6f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f0fe7e414d0>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_size, x_dims, y_dims = train_images.shape\n",
        "z_dims = np.amax(train_images) + 1 # Number of different title types\n",
        "print(z_dims)\n",
        "train_images_onehot = np.eye(z_dims, dtype='uint8')[train_images]\n",
        "print(train_images_onehot.shape) # (train_size, x_dims, y_dims, z_dims)\n",
        "\n",
        "train_images = np.zeros((train_size, MAP_SIZE, MAP_SIZE, z_dims))\n",
        "print(train_images.shape)\n",
        "\n",
        "# TODO: Change empty space encoding here if different\n",
        "train_images[:, :, :, 1] = 0.0  # Fill with empty space \n",
        "\n",
        "train_images[:train_size, :x_dims, :y_dims, :] = train_images_onehot\n",
        "print(train_images.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEH0mktqE27L",
        "outputId": "bc081036-67f5-4ccb-a527-dc5873c72d9a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "(36, 5, 5, 2)\n",
            "(36, 32, 32, 2)\n",
            "(36, 32, 32, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(np.argmax(train_images[2], axis=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "BCYDXUOXDW5u",
        "outputId": "43e5f57b-a742-45ec-935c-9544744db804"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f0fe7dbfc10>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(train_size).batch(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "oGiX48GNDhBz"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_discriminator_model(n_extra_layers=0):\n",
        "  assert MAP_SIZE % 16 == 0\n",
        "\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(layers.Conv2D(64, (4, 4), strides=(2, 2), padding='same', use_bias=False, input_shape=(MAP_SIZE, MAP_SIZE, z_dims)))\n",
        "  model.add(layers.LeakyReLU(alpha=0.2))\n",
        "\n",
        "  image_size, n_filters = MAP_SIZE / 2, 64\n",
        "\n",
        "  # Extra layers\n",
        "  for i in range(n_extra_layers):\n",
        "    model.add(layers.Conv2D(n_filters, (3, 3), strides=(1, 1), padding='same', use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "\n",
        "  while image_size > 4:\n",
        "    n_filters *= 2\n",
        "    model.add(layers.Conv2D(n_filters, (4, 4), strides=(2, 2), padding='same', use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "    image_size /= 2\n",
        "\n",
        "  # Input here is (BATCH_SIZE x 4 x 4 x n_filters)\n",
        "  model.add(layers.Conv2D(1, (4, 4), strides=(1, 1), padding='valid', use_bias=False))\n",
        "    \n",
        "  return model"
      ],
      "metadata": {
        "id": "WVU09kuKDr-M"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_generator_model(n_extra_layers=0):\n",
        "  assert MAP_SIZE % 16 == 0\n",
        "\n",
        "  noise_size = 32\n",
        "  # 32 here is the 1/2 * n_channels before last Conv2DTranspose\n",
        "  n_filters = 32 * MAP_SIZE / 4\n",
        "\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(tf.keras.Input(shape=(noise_size, )))\n",
        "  model.add(layers.Reshape((1, 1, noise_size)))\n",
        "  \n",
        "  model.add(layers.Conv2DTranspose(n_filters, (4, 4), strides=(1, 1), padding='valid', use_bias=False))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.ReLU())\n",
        "\n",
        "  image_size = 4\n",
        "  while image_size < MAP_SIZE / 2:\n",
        "    n_filters /= 2\n",
        "    model.add(layers.Conv2DTranspose(n_filters, (4, 4), strides=(2, 2), padding='same', use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.ReLU())\n",
        "    image_size *= 2\n",
        "\n",
        "  # Extra layers\n",
        "  for i in range(n_extra_layers):\n",
        "    model.add(layers.Conv2DTranspose(n_filters, (3, 3), strides=(1, 1), padding='same', use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.ReLU())\n",
        "\n",
        "  model.add(layers.Conv2DTranspose(z_dims, (4, 4), strides=(2, 2), padding='same', use_bias=False))\n",
        "  model.add(layers.ReLU())\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "Vwdu1fscDtLJ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator = make_discriminator_model()\n",
        "generator = make_generator_model()"
      ],
      "metadata": {
        "id": "hruWGrDdDxVU"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(discriminator.summary())\n",
        "print(generator.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07jKDL-WDzxd",
        "outputId": "29ae82a7-2811-457b-9a53-74f5a4f3bbe8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 16, 16, 64)        2048      \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 8, 8, 128)         131072    \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 8, 8, 128)        512       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 4, 4, 256)         524288    \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 4, 4, 256)        1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 4, 4, 256)         0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 1, 1, 1)           4096      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 663,040\n",
            "Trainable params: 662,272\n",
            "Non-trainable params: 768\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " reshape (Reshape)           (None, 1, 1, 32)          0         \n",
            "                                                                 \n",
            " conv2d_transpose (Conv2DTra  (None, 4, 4, 256)        131072    \n",
            " nspose)                                                         \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 4, 4, 256)        1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " re_lu (ReLU)                (None, 4, 4, 256)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_1 (Conv2DT  (None, 8, 8, 128)        524288    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 8, 8, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " re_lu_1 (ReLU)              (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_2 (Conv2DT  (None, 16, 16, 64)       131072    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 16, 16, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " re_lu_2 (ReLU)              (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " conv2d_transpose_3 (Conv2DT  (None, 32, 32, 2)        2048      \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " re_lu_3 (ReLU)              (None, 32, 32, 2)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 790,272\n",
            "Trainable params: 789,376\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generator(np.random.rand(1, 32)).shape)\n",
        "print(discriminator(np.random.rand(1, MAP_SIZE, MAP_SIZE, z_dims)).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uo8pT99QD1_Z",
        "outputId": "b4c071a3-a3ad-440a-af5d-a2d3d873e881"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 32, 32, 2)\n",
            "(1, 1, 1, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_discriminator_loss(real_output, generated_output):\n",
        "  real_loss = tf.reduce_mean(real_output)\n",
        "  generated_loss = tf.reduce_mean(generated_output)\n",
        "  total_loss = real_loss - generated_loss\n",
        "\n",
        "  return total_loss\n",
        "\n",
        "\n",
        "def get_generator_loss(generated_output):\n",
        "  return -tf.reduce_mean(generated_output)"
      ],
      "metadata": {
        "id": "8NBYxSMgD4sh"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator_optimizer = tf.optimizers.RMSprop(LR_D)\n",
        "generator_optimizer = tf.optimizers.RMSprop(LR_G)"
      ],
      "metadata": {
        "id": "FurIZh-MELK5"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_and_save_images(model, epoch, test_input, savefig=False):\n",
        "  predictions = model(test_input, training=False)\n",
        "\n",
        "  fig = plt.figure(figsize=(10, 10))\n",
        "\n",
        "  for i in range(predictions.shape[0]):\n",
        "    plt.subplot(4, 4, i+1)\n",
        "    plt.imshow(np.argmax(predictions[i], axis=2))\n",
        "    plt.axis('off')\n",
        "\n",
        "  if savefig:\n",
        "    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "np1ORVS3D9xJ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 5000\n",
        "noise_size = 32\n",
        "num_examples = 8\n",
        "\n",
        "# Use same random vector to see evolution of generated images over time\n",
        "random_vector_for_generation = tf.random.normal([num_examples, noise_size])"
      ],
      "metadata": {
        "id": "dQWKMIQqD_v8"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(images, update_generator=False):\n",
        "  # Generating noise from a normal distribution\n",
        "  noise = tf.random.normal([BATCH_SIZE, noise_size])\n",
        "\n",
        "  for w in discriminator.trainable_variables:\n",
        "    w.assign(tf.clip_by_value(w, -0.01, 0.01))\n",
        "    \n",
        "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "    generated_images = generator(noise, training=True)\n",
        "    real_output = discriminator(images, training=True)\n",
        "    generated_output = discriminator(generated_images, training=True)\n",
        "\n",
        "    gen_loss = get_generator_loss(generated_output)\n",
        "    disc_loss = get_discriminator_loss(real_output, generated_output)\n",
        "        \n",
        "    gradients_of_discriminator = disc_tape.gradient(-disc_loss, discriminator.trainable_variables)\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "    if update_generator:\n",
        "      gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "      generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "\n",
        "  return gen_loss, disc_loss"
      ],
      "metadata": {
        "id": "4huaL8CoEAdK"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzIiThjJEQiC",
        "outputId": "3a1de6e2-ce1d-4610-ea6a-2cacde8d294c"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataset, epochs):\n",
        "  gen_iterations = 0\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "    disc_iterations = 0\n",
        "    for i, images in enumerate(dataset):\n",
        "      if disc_iterations == 0:\n",
        "        if gen_iterations < 25 or gen_iterations % 500 == 0:\n",
        "          disc_iterations = 100\n",
        "        else:\n",
        "          disc_iterations = 5\n",
        "      if disc_iterations == 1 or i == len(dataset) - 1:\n",
        "        gen_loss, disc_loss = train_step(images, True)\n",
        "        gen_iterations += 1\n",
        "      else:\n",
        "        gen_loss, disc_loss = train_step(images)\n",
        "      disc_iterations -= 1\n",
        "\n",
        "    display.clear_output(wait=True)\n",
        "    # Save generator every 500 epochs\n",
        "    if (epoch + 1) % 500 == 0:\n",
        "      generate_and_save_images(generator, epoch + 1, \n",
        "                               random_vector_for_generation, True)\n",
        "      generator.save('models/generator_baseline_' + str(epoch + 1))\n",
        "    else:\n",
        "      generate_and_save_images(generator, epoch + 1, \n",
        "                               random_vector_for_generation)\n",
        "\n",
        "    print ('Time taken for epoch {} is {} sec'.format(epoch + 1, \n",
        "                                                      time.time() - start))\n",
        "    print(\"Generator Loss: \", gen_loss)\n",
        "    print(\"Discriminator Loss: \", disc_loss)\n",
        "  # Generate after the final epoch\n",
        "  display.clear_output(wait=True)\n",
        "  generate_and_save_images(generator,\n",
        "                          epochs,\n",
        "                          random_vector_for_generation)"
      ],
      "metadata": {
        "id": "PbIJKacCEdSa"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(train_dataset, EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "KLay2pvNEixa",
        "outputId": "3b6eba8f-be4a-4ab0-fee9-fb31dc2aff78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 8 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken for epoch 4921 is 1.3085994720458984 sec\n",
            "Generator Loss:  tf.Tensor(-0.09746687, shape=(), dtype=float32)\n",
            "Discriminator Loss:  tf.Tensor(0.0004978627, shape=(), dtype=float32)\n"
          ]
        }
      ]
    }
  ]
}